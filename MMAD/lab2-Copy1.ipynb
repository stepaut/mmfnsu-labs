{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "771938e8",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2 : «Наивный» байесовский классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca149d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as qda\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import sklearn\n",
    "from scipy import linalg as npl\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from sklearn.metrics import ConfusionMatrixDisplay as cmd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae971a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### methods\n",
    "\n",
    "def GetProbByColumn(X_, y_, column, j, alpha = 0):\n",
    "    prob  = {}\n",
    "    x = X_[column]\n",
    "    x = x[y_ == j]\n",
    "    unique = X_[column].unique()\n",
    "    k = len(unique)\n",
    "    for i in unique:\n",
    "        prob[i] = (x[x == i].count() + alpha) / (x.count() + alpha * k)\n",
    "    return prob\n",
    "\n",
    "def Predict2(X_, y_, column):\n",
    "    yPred = []\n",
    "    prob0 = GetProbByColumn(X_, y_, column, 'e')\n",
    "    prob1 = GetProbByColumn(X_, y_, column, 'p')\n",
    "    c = y_.count()\n",
    "    p0 = y_[y_ == 'e'].count() / c\n",
    "    p1 = y_[y_ == 'p'].count() / c\n",
    "    for k in X_[column]:\n",
    "        if p0 * prob0[k] < p1 * prob1[k]:\n",
    "            yPred.append('p')\n",
    "        else:\n",
    "            yPred.append('e')\n",
    "    return np.array(yPred)\n",
    "\n",
    "def GetProbs(X_, y_, j, alpha):\n",
    "    probs = {}\n",
    "    for col in X_.columns:\n",
    "        probs[col] = (GetProbByColumn(X_, y_, col, j, alpha))\n",
    "    return probs\n",
    "\n",
    "def Predict4(X_, y_, alpha):\n",
    "    y_pred = []\n",
    "    prob0 = GetProbs(X_, y_, 'e', alpha)\n",
    "    prob1 = GetProbs(X_, y_, 'p', alpha)\n",
    "    c = y_.count()\n",
    "    p0 = y_[y_ == 'e'].count() / c\n",
    "    p1 = y_[y_ == 'p'].count() / c\n",
    "    for i in range(len(X_)):\n",
    "        p0_ = p0\n",
    "        p1_ = p1\n",
    "        for col in X_.columns:\n",
    "            p0_ *= prob0[col][X_[i:i+1][col].values[0]]\n",
    "            p1_ *= prob1[col][X_[i:i+1][col].values[0]]\n",
    "        if p0 * p0_ < p1 * p1_:\n",
    "            y_pred.append('p')\n",
    "        else:\n",
    "            y_pred.append('e')\n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9eed1d8",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5d95bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V=83 => вариант 12\n",
    "\n",
    "df = pd.read_csv('mushrooms.csv')\n",
    "df = df[['stalk-surface-above-ring', 'stalk-surface-below-ring','stalk-color-above-ring', 'stalk-color-below-ring','veil-type','class']]\n",
    "X = df.drop(columns=['class'])\n",
    "y = df['class']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X:\n",
    "    sns.catplot(x = i, data=df, hue='class',kind = 'count' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1307b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4dfedaa",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = pd.DataFrame(columns = ['score_test','score_train'])\n",
    "for col in X.columns:\n",
    "    G = G.append({'score_test' : accuracy_score(y_test, Predict2(X_test, y_test, col)), 'score_train' : accuracy_score(y_train, Predict2(X_train, y_train, col))},ignore_index=True)\n",
    "G = G.set_index(X.columns)\n",
    "G"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a45bdb4",
   "metadata": {},
   "source": [
    "видно, что самая информативная переменная - **stalk-surface-above-ring**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2426a297",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ddff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_ohe = y.copy()\n",
    "#y_ohe = LabelEncoder().fit_transform(y_ohe)\n",
    "\n",
    "#X_ohe = X.copy()\n",
    "#X_ohe['veil-type']=LabelEncoder().fit_transform(X_ohe['veil-type'])\n",
    "#X_ohe = pd.get_dummies(data=X_ohe)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_ohe, y_ohe, random_state=1234)\n",
    "\n",
    "X_train_ohe = pd.get_dummies(X_train)\n",
    "X_test_ohe = pd.get_dummies(X_test)\n",
    "y_train_ohe = y_train\n",
    "y_test_ohe = y_test\n",
    "\n",
    "model = sklearn.naive_bayes.BernoulliNB()\n",
    "model.fit(X_train_ohe,y_train_ohe)\n",
    "score = model.score(X_test_ohe,y_test_ohe)\n",
    "print('Score:', score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cefa88f3",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f1c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(X_, col): \n",
    "    l_0 = 0\n",
    "    b_0 = 0\n",
    "    for j in X_.columns:\n",
    "        b_j =0\n",
    "        b_j = np.log(p[j]*(1-q[j])/(q[j]*(1-p[j])))\n",
    "        l_0+=b_j*col[j]\n",
    "        b_0+=np.log((1-p[j])/(1-q[j]))\n",
    "    b_0 += np.log(P1/P2)\n",
    "    return (l_0+b_0)\n",
    "\n",
    "def Predict4task(X_, y_, X_tr, y_tr):\n",
    "    p = {}\n",
    "    q = {}\n",
    "    y_tr_len = len(y_tr)\n",
    "    P1 = len(y_tr[y_tr=='p'])/y_tr_len\n",
    "    P2 = len(y_tr[y_tr=='e'])/y_tr_len\n",
    "    for j in X_tr.columns:\n",
    "        p[j] = (X_tr[y_tr=='p'][j].mean())\n",
    "        q[j] = (X_tr[y_tr=='e'][j].mean())\n",
    "        if(q[j]==1):\n",
    "            q[j] = 1.-1e-10\n",
    "        if(p[j]==1):\n",
    "            p[j] = 1.-1e-10\n",
    "        if(q[j]==0):\n",
    "            q[j] = 1e-20\n",
    "        if(p[j]==0):\n",
    "            p[j] = 1e-20\n",
    "    a = []\n",
    "    for i in X_.index:\n",
    "        a.append(pred(X_, X_.loc[i]))\n",
    "    b = []\n",
    "    for i in a:\n",
    "        if(i>=0):\n",
    "            b.append('p')\n",
    "        else:\n",
    "            b.append('e')\n",
    "    b = np.array(b)\n",
    "    err = 0\n",
    "    for i in range(len(b)):\n",
    "        if(b[i]!=y_.iloc[i]):\n",
    "            err+=1\n",
    "    score = 1- err/len(b)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a29d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score:', Predict4task(X_test_ohe, y_test_ohe, X_train_ohe, y_train_ohe))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3456fe8",
   "metadata": {},
   "source": [
    "видно, что результат совпадает с библиотечным методом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff95f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)\n",
    "\n",
    "print('test:', accuracy_score(Predict4(X_test, y_test, 1), y_test))\n",
    "print('train:', accuracy_score(Predict4(X_train, y_train, 1), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89539408",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_o = X.copy()\n",
    "y_o = y.copy()\n",
    "enc = OrdinalEncoder()\n",
    "X_o = enc.fit_transform(X_o)\n",
    "y_o =  enc.fit_transform(pd.DataFrame(y_o))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_o, y_o, random_state=1234)\n",
    "print(y_train)\n",
    "model = sklearn.naive_bayes.CategoricalNB().fit(X_train,y_train)\n",
    "print('test:', accuracy_score(y_test, model.predict(X_test)))\n",
    "print('train:', accuracy_score(y_train, model.predict(X_train)))\n",
    "\n",
    "X_c = X.copy()\n",
    "y_c = y.copy()\n",
    "for i in X_c:\n",
    "    X_c[i]=LabelEncoder().fit_transform(df[i])\n",
    "y_c = LabelEncoder().fit_transform(y_c)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_c, y_c,random_state=1234)\n",
    "print(y_train)\n",
    "model = sklearn.naive_bayes.CategoricalNB().fit(X_train,y_train)\n",
    "print('test:', accuracy_score(y_test, model.predict(X_test)))\n",
    "print('train:', accuracy_score(y_train, model.predict(X_train)))\n",
    "\n",
    "y_ohe = y.copy()\n",
    "y_ohe = LabelEncoder().fit_transform(y_ohe)\n",
    "X_ohe = X.copy()\n",
    "X_ohe['veil-type']=LabelEncoder().fit_transform(X_ohe['veil-type'])\n",
    "X_ohe = pd.get_dummies(data=X_ohe)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ohe, y_ohe, random_state=1234)\n",
    "print(y_train)\n",
    "model = sklearn.naive_bayes.BernoulliNB().fit(X_train,y_train)\n",
    "print('test:', accuracy_score(y_test, model.predict(X_test)))\n",
    "print('train:', accuracy_score(y_train, model.predict(X_train)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)\n",
    "print(y_train)\n",
    "print('test:', accuracy_score(Predict4(X_test, y_test, 1), y_test))\n",
    "print('train:', accuracy_score(Predict4(X_train, y_train, 1), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04394ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad3eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_col(X,y,column,j, alpha = 0):\n",
    "    prob  = {}\n",
    "    x = X[column]\n",
    "    x = x[y == j]\n",
    "    k = len(X[column].unique())\n",
    "    for i in X[column].unique():\n",
    "        prob[i] = (x[x == i].count() + alpha) / (x.count() + alpha * k)\n",
    "    return prob\n",
    "\n",
    "def get_prob(X,y,j,alpha = 0):\n",
    "    prob = {}\n",
    "    for col in X.columns:\n",
    "        prob[col] = (get_prob_col(X,y,col,j,alpha))\n",
    "    return prob\n",
    "\n",
    "def predict(X,y, alpha = 0):\n",
    "    prob0 = get_prob(X,y,'e',alpha= alpha)\n",
    "    prob1 = get_prob(X,y,'p',alpha = alpha)\n",
    "    p0 = y[y == 'e'].count() / y.count()\n",
    "    p1 = y[y == 'p'].count() / y.count()\n",
    "    y_pred = []\n",
    "    for i in range(len(X)):\n",
    "        prod0 = p0\n",
    "        prod1 = p1\n",
    "        for col in X.columns:\n",
    "            prod0 *= prob0[col][X[i:i+1][col].values[0]]\n",
    "            prod1 *= prob1[col][X[i:i+1][col].values[0]]\n",
    "        if p0 * prod0 < p1 * prod1:\n",
    "            y_pred.append('p')\n",
    "        else:\n",
    "            y_pred.append('e')\n",
    "    return y_pred\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1234)\n",
    "print('test:',accuracy_score(predict(X_test,y_test, alpha= 1), y_test))\n",
    "print('train:',accuracy_score(predict(X_train,y_train, alpha= 1), y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88584e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_col1(column,j, alpha = 0):\n",
    "    prob  = {}\n",
    "    x = X[column]\n",
    "    x = x[y == j]\n",
    "    k = len(X[column].unique())\n",
    "    for i in X[column].unique():\n",
    "        prob[i] = (x[x == i].count() + alpha) / (x.count() + alpha * k)\n",
    "    return prob\n",
    "\n",
    "def predict1(X,column):\n",
    "    print('aaa')\n",
    "    y_pred = []\n",
    "    prob0 = get_prob_col1(column,'e')\n",
    "    prob1 = get_prob_col1(column,'p')\n",
    "    p0 = y[y == 'e'].count() / y.count()\n",
    "    p1 = y[y == 'p'].count() / y.count()\n",
    "    for k in X[column]:\n",
    "        if p0 * prob0[k] < p1 * prob1[k]:\n",
    "            y_pred.append('p')\n",
    "        else:\n",
    "            y_pred.append('e')\n",
    "    return np.array(y_pred)\n",
    "\n",
    "def get_prob1(j,alpha = 0):\n",
    "    prob = {}\n",
    "    for col in X.columns:\n",
    "        prob[col] = (get_prob_col1(col,j,alpha))\n",
    "    return prob\n",
    "\n",
    "def predict1(X, alpha = 0):\n",
    "    prob0 = get_prob1('e',alpha= alpha)\n",
    "    prob1 = get_prob1('p',alpha = alpha)\n",
    "    p0 = y[y == 'e'].count() / y.count()\n",
    "    p1 = y[y == 'p'].count() / y.count()\n",
    "    y_pred = []\n",
    "    for i in range(len(X)):\n",
    "        prod0 = p0\n",
    "        prod1 = p1\n",
    "        for col in X.columns:\n",
    "            prod0 *= prob0[col][X[i:i+1][col].values[0]]\n",
    "            prod1 *= prob1[col][X[i:i+1][col].values[0]]\n",
    "        if p0 * prod0 < p1 * prod1:\n",
    "            y_pred.append('p')\n",
    "        else:\n",
    "            y_pred.append('e')\n",
    "    return y_pred\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)\n",
    "print('test:',accuracy_score(predict1(X_test, alpha= 1), y_test))\n",
    "print('train:',accuracy_score(predict1(X_train, alpha= 1), y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
